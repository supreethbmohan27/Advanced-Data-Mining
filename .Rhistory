# Train XGBoost model with current hyperparameters
xgb_model <- xgboost(data = dtrain,
params = list(
objective = "binary:logistic",  # For binary classification
eval_metric = "error",           # Evaluation metric
max_depth = param_grid[[1]][i],   # Current max_depth value
min_child_weight = param_grid[[2]][j]  # Current min_child_weight value
),
nrounds = 6)  # Number of boosting rounds
# Make predictions on training, validation, and testing data
train_pred <- predict(xgb_model, dtrain)
cv_pred <- predict(xgb_model, dcv)
test_pred <- predict(xgb_model, dtest)
# Calculate error for each dataset
train_errors[i, j] <- mean(train_pred != BreastCancer.train$Class)
cv_errors[i, j] <- mean(cv_pred != BreastCancer.validation$Class)
test_errors[i, j] <- mean(test_pred != BreastCancer.test$Class)
}
}
set.seed(530) # For reproducibility
train_indices <- sample(1:nrow(BreastCancer), 0.8 * nrow(BreastCancer))
validation_indices <- setdiff(1:nrow(BreastCancer), train_indices)
# Create DMatrix objects for training and validation data
dtrain <- xgb.DMatrix(data = as.matrix(BreastCancer[train_indices, -1]), label = BreastCancer[train_indices, "Class"])
best_nrounds <- which.min(cv_errors)
best_nrounds
# Load data
BreastCancer <- read_excel("C:/Users/supre/Desktop/ADM/Project/ADM Project/breastcancer/breastcancer2.xlsx")
BreastCancer <- na.omit(BreastCancer) # Remove NA
BreastCancer$tumorsize <- sapply(strsplit(BreastCancer$tumorsize, "-"), function(x) mean(as.numeric(x)))
# Ensure 'node-caps' is a factor with levels 'yes' and 'no'
BreastCancer$nodecaps <- factor(BreastCancer$nodecaps, levels = c("yes", "no"))
# Convert 'age' column to numeric by taking the midpoint of the range
BreastCancer$age <- sapply(strsplit(BreastCancer$age, "-"), function(x) mean(as.numeric(x)))
# Ensure 'age' is treated as numeric
BreastCancer$age <- as.numeric(BreastCancer$age)
BreastCancer$invnodes <- sapply(strsplit(BreastCancer$invnodes, "-"), function(x) mean(as.numeric(x)))
# Ensure 'inv-nodes' is treated as numeric
BreastCancer$invnodes <- as.numeric(BreastCancer$invnodes)
# Factorize non-numeric columns
#BreastCancer$age <- factor(BreastCancer$age, levels = c("10-19", "20-29", "30-39", "40-49", "50-59", "60-69", "70-79", "80-89", "90-99"))
BreastCancer$menopause <- factor(BreastCancer$menopause, levels = c("lt40", "ge40", "premeno"))
#BreastCancer$tumor.size <- factor(BreastCancer$tumor.size, levels = c("0-4", "5-9", "10-14", "15-19", "20-24", "25-29", "30-34", "35-39", "40-44", "45-49", "50-54", "55-59"))
#BreastCancer$inv.nodes <- factor(BreastCancer$inv.nodes, levels = c("0-2", "3-5", "6-8", "9-11", "12-14", "15-17", "18-20", "21-23", "24-26", "27-29", "30-32", "33-35", "36-39"))
BreastCancer$nodecaps <- factor(BreastCancer$nodecaps, levels = c("yes", "no"))
BreastCancer$breast <- factor(BreastCancer$breast, levels = c("left", "right"))
BreastCancer$breastquad <- factor(BreastCancer$breastquad, levels = c("leftup", "leftlow", "rightup", "rightlow", "central"))
BreastCancer$irradiat <- factor(BreastCancer$irradiat, levels = c("yes", "no"))
# Convert factor levels to numeric values
BreastCancer$age <- as.numeric(BreastCancer$age)
BreastCancer$menopause <- as.numeric(BreastCancer$menopause)
BreastCancer$tumorsize <- as.numeric(BreastCancer$tumorsize)
BreastCancer$invnodes <- as.numeric(BreastCancer$invnodes)
BreastCancer$nodecaps <- as.numeric(BreastCancer$nodecaps)
BreastCancer$breast <- as.numeric(BreastCancer$breast)
BreastCancer$breastquad <- as.numeric(BreastCancer$breastquad)
BreastCancer$irradiat <- as.numeric(BreastCancer$irradiat)
# Convert "no-recurrence-events" to 0 and "recurrence-events" to 1
BreastCancer$Class <- as.numeric(ifelse(BreastCancer$Class == "recurrence-events", 1, 0))
# Set seed for reproducibility
set.seed(530)
Random.seed <- c("Mersenne-Twister", 530)
# Split data into training and testing sets
BreastCancer.split <- sample(1:nrow(BreastCancer), size = nrow(BreastCancer) * 0.8)
BreastCancer.train <- BreastCancer[BreastCancer.split,]
BreastCancer.test <- BreastCancer[-BreastCancer.split,]
# Convert data to matrix
dtrain <- xgb.DMatrix(data = as.matrix(BreastCancer.train[, -1]), label = BreastCancer.train$Class)
dtest <- xgb.DMatrix(data = as.matrix(BreastCancer.test[, -1]))
# Set hyperparameters
params <- list(
objective = "binary:logistic",  # For binary classification
eval_metric = "error"            # Evaluation metric
)
xgb_model_cv <- xgb.cv(data = dtrain,
params = params,
nfold = 5,
nrounds = 6,            # Number of boosting rounds
early_stopping_rounds = 5,
seed = 530,
metrics = "error",       # Specify the evaluation metric for cross-validation
maximize = FALSE)        # Error is minimized
# Get the cross-validation error for each boosting round
cv_errors <- xgb_model_cv$evaluation_log$test_error_mean
best_nrounds <- which.min(cv_errors)
best_nrounds
# Train the final model with the optimal number of boosting rounds
xgb_model <- xgboost(data = dtrain,
params = params,
nrounds = best_nrounds)
predictions <- predict(xgb_model, dtest)
# Convert predictions to class labels
predicted_labels <- ifelse(predictions > 0.5, 1, 0)
# Evaluate the model
accuracy <- mean(predicted_labels == BreastCancer.test$Class)
# Predictions on the train set
predictions_train <- predict(xgb_model, as.matrix(BreastCancer.train[, -1]))
predictions_train <- ifelse(predictions_train > 0.5, 1, 0)
# Confusion matrix for train set
conf_mat_train <- table(BreastCancer.train$Class, predictions_train)
conf_mat_train
acc_xgb_train <- sum(diag(conf_mat_train)) / sum(conf_mat_train)
sensitivity_xgb_train <- conf_mat_train[1, 1] / sum(conf_mat_train[1, ])
specificity_xgb_train <- conf_mat_train[2, 2] / sum(conf_mat_train[2, ])
ppv_xgb_train <- conf_mat_train[1, 1] / sum(conf_mat_train[, 1])
npv_xgb_train <- conf_mat_train[2, 2] / sum(conf_mat_train[, 2])
# Predictions on the test set
predictions_test <- predict(xgb_model, as.matrix(BreastCancer.test[, -1]))
predictions_test <- ifelse(predictions_test > 0.5, 1, 0)
# Confusion matrix for test set
conf_mat_test <- table(BreastCancer.test$Class, predictions_test)
acc_xgb_test <- sum(diag(conf_mat_test)) / sum(conf_mat_test)
sensitivity_xgb_test <- conf_mat_test[1, 1] / sum(conf_mat_test[1, ])
specificity_xgb_test <- conf_mat_test[2, 2] / sum(conf_mat_test[2, ])
ppv_xgb_test <- conf_mat_test[1, 1] / sum(conf_mat_test[, 1])
npv_xgb_test <- conf_mat_test[2, 2] / sum(conf_mat_test[, 2])
conf_mat_test
predictions_all <- predict(xgb_model, as.matrix(BreastCancer[, -1]))
predictions_all <- ifelse(predictions_all > 0.5, 1, 0)
conf_mat_all <- table(BreastCancer$Class, predictions_all)
acc_xgb_all <- sum(diag(conf_mat_all)) / sum(conf_mat_all)
sensitivity_xgb_all <- conf_mat_all[1, 1] / sum(conf_mat_all[1, ])
specificity_xgb_all <- conf_mat_all[2, 2] / sum(conf_mat_all[2, ])
ppv_xgb_all <- conf_mat_all[1, 1] / sum(conf_mat_all[, 1])
npv_xgb_all <- conf_mat_all[2, 2] / sum(conf_mat_all[, 2])
# Print the metrics for the XGBoost model
acc_xgb_train
sensitivity_xgb_train
specificity_xgb_train
ppv_xgb_train
npv_xgb_train
acc_xgb_test
sensitivity_xgb_test
specificity_xgb_test
ppv_xgb_test
npv_xgb_test
acc_xgb_all
sensitivity_xgb_all
specificity_xgb_all
ppv_xgb_all
npv_xgb_all
# Predict probabilities for train, test, and all datasets
train_pred_prob <- predict(xgb_model, as.matrix(BreastCancer.train[, -1]))
test_pred_prob <- predict(xgb_model, as.matrix(BreastCancer.test[, -1]))
all_pred_prob <- predict(xgb_model, as.matrix(BreastCancer[, -1]))
# Calculate ROC curves
train_roc <- roc(BreastCancer.train$Class, train_pred_prob)
test_roc <- roc(BreastCancer.test$Class, test_pred_prob)
all_roc <- roc(BreastCancer$Class, all_pred_prob)
# Check the number of points in the ROC curve
num_points <- length(train_roc$thresholds)
print(num_points)
summary(train_pred_prob)
# Check the range
min_prob <- min(train_pred_prob)
max_prob <- max(train_pred_prob)
print(min_prob)
print(max_prob)
# Smooth ROC curves
smoothed_train_roc <- smooth(train_roc)
smoothed_test_roc <- smooth(test_roc)
smoothed_all_roc <- smooth(all_roc)
# Plot ROC curves
plot(train_roc, col = "blue", main = "ROC Curves for XGBoost",
xlab = "False Positive Rate", ylab = "True Positive Rate")
plot(smoothed_train_roc, col = "lightblue", add = TRUE)
plot(test_roc, col = "red", add = TRUE)
plot(smoothed_test_roc, col = "pink", add = TRUE)
plot(all_roc, col = "green", add = TRUE)
plot(smoothed_all_roc, col = "lightgreen", add = TRUE)
# Calculate AUC for each curve
train_auc <- round(auc(train_roc), 2)
test_auc <- round(auc(test_roc), 2)
all_auc <- round(auc(all_roc), 2)
smoothed_train_auc <- round(auc(smoothed_train_roc), 2)
smoothed_test_auc <- round(auc(smoothed_test_roc), 2)
smoothed_all_auc <- round(auc(smoothed_all_roc), 2)
# Add legend with AUC values
legend("bottomright", legend = c(
paste("Train (Empirical)", "AUC =", train_auc),
paste("Train (Smoothed)", "AUC =", smoothed_train_auc),
paste("Test (Empirical)", "AUC =", test_auc),
paste("Test (Smoothed)", "AUC =", smoothed_test_auc),
paste("All (Empirical)", "AUC =", all_auc),
paste("All (Smoothed)", "AUC =", smoothed_all_auc)
), col = c("blue", "lightblue", "red", "pink", "green", "lightgreen"), lwd = 2, cex = 0.6)
conf_mat_all
# Load data
BreastCancer <- read_excel("C:/Users/supre/Desktop/ADM/Project/ADM Project/breastcancer/breastcancer2.xlsx")
BreastCancer <- na.omit(BreastCancer) # Remove NA
BreastCancer$tumorsize <- sapply(strsplit(BreastCancer$tumorsize, "-"), function(x) mean(as.numeric(x)))
# Ensure 'node-caps' is a factor with levels 'yes' and 'no'
BreastCancer$nodecaps <- factor(BreastCancer$nodecaps, levels = c("yes", "no"))
# Convert 'age' column to numeric by taking the midpoint of the range
BreastCancer$age <- sapply(strsplit(BreastCancer$age, "-"), function(x) mean(as.numeric(x)))
# Ensure 'age' is treated as numeric
BreastCancer$age <- as.numeric(BreastCancer$age)
BreastCancer$invnodes <- sapply(strsplit(BreastCancer$invnodes, "-"), function(x) mean(as.numeric(x)))
# Ensure 'inv-nodes' is treated as numeric
BreastCancer$invnodes <- as.numeric(BreastCancer$invnodes)
# Factorize non-numeric columns
#BreastCancer$age <- factor(BreastCancer$age, levels = c("10-19", "20-29", "30-39", "40-49", "50-59", "60-69", "70-79", "80-89", "90-99"))
BreastCancer$menopause <- factor(BreastCancer$menopause, levels = c("lt40", "ge40", "premeno"))
#BreastCancer$tumor.size <- factor(BreastCancer$tumor.size, levels = c("0-4", "5-9", "10-14", "15-19", "20-24", "25-29", "30-34", "35-39", "40-44", "45-49", "50-54", "55-59"))
#BreastCancer$inv.nodes <- factor(BreastCancer$inv.nodes, levels = c("0-2", "3-5", "6-8", "9-11", "12-14", "15-17", "18-20", "21-23", "24-26", "27-29", "30-32", "33-35", "36-39"))
BreastCancer$nodecaps <- factor(BreastCancer$nodecaps, levels = c("yes", "no"))
BreastCancer$breast <- factor(BreastCancer$breast, levels = c("left", "right"))
BreastCancer$breastquad <- factor(BreastCancer$breastquad, levels = c("leftup", "leftlow", "rightup", "rightlow", "central"))
BreastCancer$irradiat <- factor(BreastCancer$irradiat, levels = c("yes", "no"))
# Convert factor levels to numeric values
BreastCancer$age <- as.numeric(BreastCancer$age)
BreastCancer$menopause <- as.numeric(BreastCancer$menopause)
BreastCancer$tumorsize <- as.numeric(BreastCancer$tumorsize)
BreastCancer$invnodes <- as.numeric(BreastCancer$invnodes)
BreastCancer$nodecaps <- as.numeric(BreastCancer$nodecaps)
BreastCancer$breast <- as.numeric(BreastCancer$breast)
BreastCancer$breastquad <- as.numeric(BreastCancer$breastquad)
BreastCancer$irradiat <- as.numeric(BreastCancer$irradiat)
# Convert "no-recurrence-events" to 0 and "recurrence-events" to 1
BreastCancer$Class <- as.numeric(ifelse(BreastCancer$Class == "recurrence-events", 1, 0))
# Set seed for reproducibility
set.seed(530)
Random.seed <- c("Mersenne-Twister", 530)
BreastCancer <- na.omit(BreastCancer)
# Split data into training and testing sets
BreastCancer.split <- sample(1:nrow(BreastCancer), size = nrow(BreastCancer) * 0.8)
BreastCancer.train <- BreastCancer[BreastCancer.split,]
BreastCancer.test <- BreastCancer[-BreastCancer.split,]
# Convert data to matrix
dtrain <- xgb.DMatrix(data = as.matrix(BreastCancer.train[, -1]), label = BreastCancer.train$Class)
dtest <- xgb.DMatrix(data = as.matrix(BreastCancer.test[, -1]))
# Set hyperparameters
params <- list(
objective = "binary:logistic",  # For binary classification
eval_metric = "error"            # Evaluation metric
)
xgb_model_cv <- xgb.cv(data = dtrain,
params = params,
nfold = 5,
nrounds = 6,            # Number of boosting rounds
early_stopping_rounds = 5,
seed = 530,
metrics = "error",       # Specify the evaluation metric for cross-validation
maximize = FALSE)        # Error is minimized
# Get the cross-validation error for each boosting round
cv_errors <- xgb_model_cv$evaluation_log$test_error_mean
xgb_model_cv$evaluation_log
best_nrounds <- which.min(cv_errors)
best_nrounds
# Train the final model with the optimal number of boosting rounds
xgb_model <- xgboost(data = dtrain,
params = params,
nrounds = best_nrounds)
# Make predictions on the test data
predictions <- predict(xgb_model, dtest)
# Convert predictions to class labels
predicted_labels <- ifelse(predictions > 0.5, 1, 0)
# Evaluate the model
accuracy <- mean(predicted_labels == BreastCancer.test$Class)
# Predictions on the train set
predictions_train <- predict(xgb_model, as.matrix(BreastCancer.train[, -1]))
predictions_train <- ifelse(predictions_train > 0.5, 1, 0)
# Confusion matrix for train set
conf_mat_train <- table(BreastCancer.train$Class, predictions_train)
acc_xgb_train <- sum(diag(conf_mat_train)) / sum(conf_mat_train)
sensitivity_xgb_train <- conf_mat_train[1, 1] / sum(conf_mat_train[1, ])
specificity_xgb_train <- conf_mat_train[2, 2] / sum(conf_mat_train[2, ])
ppv_xgb_train <- conf_mat_train[1, 1] / sum(conf_mat_train[, 1])
npv_xgb_train <- conf_mat_train[2, 2] / sum(conf_mat_train[, 2])
# Predictions on the test set
predictions_test <- predict(xgb_model, as.matrix(BreastCancer.test[, -1]))
predictions_test <- ifelse(predictions_test > 0.5, 1, 0)
# Confusion matrix for test set
conf_mat_test <- table(BreastCancer.test$Class, predictions_test)
acc_xgb_test <- sum(diag(conf_mat_test)) / sum(conf_mat_test)
sensitivity_xgb_test <- conf_mat_test[1, 1] / sum(conf_mat_test[1, ])
specificity_xgb_test <- conf_mat_test[2, 2] / sum(conf_mat_test[2, ])
ppv_xgb_test <- conf_mat_test[1, 1] / sum(conf_mat_test[, 1])
npv_xgb_test <- conf_mat_test[2, 2] / sum(conf_mat_test[, 2])
# Confusion matrix for all dataset
predictions_all <- predict(xgb_model, as.matrix(BreastCancer[, -1]))
predictions_all <- ifelse(predictions_all > 0.5, 1, 0)
conf_mat_all <- table(BreastCancer$Class, predictions_all)
acc_xgb_all <- sum(diag(conf_mat_all)) / sum(conf_mat_all)
sensitivity_xgb_all <- conf_mat_all[1, 1] / sum(conf_mat_all[1, ])
specificity_xgb_all <- conf_mat_all[2, 2] / sum(conf_mat_all[2, ])
ppv_xgb_all <- conf_mat_all[1, 1] / sum(conf_mat_all[, 1])
npv_xgb_all <- conf_mat_all[2, 2] / sum(conf_mat_all[, 2])
# Print the metrics for the XGBoost model
acc_xgb_train
sensitivity_xgb_train
specificity_xgb_train
ppv_xgb_train
npv_xgb_train
acc_xgb_test
sensitivity_xgb_test
specificity_xgb_test
ppv_xgb_test
npv_xgb_test
acc_xgb_all
sensitivity_xgb_all
specificity_xgb_all
ppv_xgb_all
npv_xgb_all
conf_mat_train
conf_mat_test
conf_mat_all
# Predict probabilities for train, test, and all datasets
train_pred_prob <- predict(xgb_model, as.matrix(BreastCancer.train[, -1]))
test_pred_prob <- predict(xgb_model, as.matrix(BreastCancer.test[, -1]))
all_pred_prob <- predict(xgb_model, as.matrix(BreastCancer[, -1]))
# Calculate ROC curves
train_roc <- roc(BreastCancer.train$Class, train_pred_prob)
test_roc <- roc(BreastCancer.test$Class, test_pred_prob)
all_roc <- roc(BreastCancer$Class, all_pred_prob)
# Check the number of points in the ROC curve
num_points <- length(train_roc$thresholds)
print(num_points)
summary(train_pred_prob)
# Check the range
min_prob <- min(train_pred_prob)
max_prob <- max(train_pred_prob)
print(min_prob)
print(max_prob)
# Smooth ROC curves
smoothed_train_roc <- smooth(train_roc)
smoothed_test_roc <- smooth(test_roc)
smoothed_all_roc <- smooth(all_roc)
# Plot ROC curves
plot(train_roc, col = "blue", main = "ROC Curves for XGBoost",
xlab = "False Positive Rate", ylab = "True Positive Rate")
plot(smoothed_train_roc, col = "lightblue", add = TRUE)
plot(test_roc, col = "red", add = TRUE)
plot(smoothed_test_roc, col = "pink", add = TRUE)
plot(all_roc, col = "green", add = TRUE)
plot(smoothed_all_roc, col = "lightgreen", add = TRUE)
# Calculate AUC for each curve
train_auc <- round(auc(train_roc), 2)
test_auc <- round(auc(test_roc), 2)
all_auc <- round(auc(all_roc), 2)
smoothed_train_auc <- round(auc(smoothed_train_roc), 2)
smoothed_test_auc <- round(auc(smoothed_test_roc), 2)
smoothed_all_auc <- round(auc(smoothed_all_roc), 2)
# Add legend with AUC values
legend("bottomright", legend = c(
paste("Train (Empirical)", "AUC =", train_auc),
paste("Train (Smoothed)", "AUC =", smoothed_train_auc),
paste("Test (Empirical)", "AUC =", test_auc),
paste("Test (Smoothed)", "AUC =", smoothed_test_auc),
paste("All (Empirical)", "AUC =", all_auc),
paste("All (Smoothed)", "AUC =", smoothed_all_auc)
), col = c("blue", "lightblue", "red", "pink", "green", "lightgreen"), lwd = 2, cex = 0.8)
# Load data
BreastCancer <- read_excel("C:/Users/supre/Desktop/ADM/Project/ADM Project/breastcancer/breastcancer2.xlsx")
BreastCancer <- na.omit(BreastCancer) # Remove NA
BreastCancer$tumorsize <- sapply(strsplit(BreastCancer$tumorsize, "-"), function(x) mean(as.numeric(x)))
# Ensure 'node-caps' is a factor with levels 'yes' and 'no'
BreastCancer$nodecaps <- factor(BreastCancer$nodecaps, levels = c("yes", "no"))
# Convert 'age' column to numeric by taking the midpoint of the range
BreastCancer$age <- sapply(strsplit(BreastCancer$age, "-"), function(x) mean(as.numeric(x)))
# Ensure 'age' is treated as numeric
BreastCancer$age <- as.numeric(BreastCancer$age)
BreastCancer$invnodes <- sapply(strsplit(BreastCancer$invnodes, "-"), function(x) mean(as.numeric(x)))
# Ensure 'inv-nodes' is treated as numeric
BreastCancer$invnodes <- as.numeric(BreastCancer$invnodes)
# Factorize non-numeric columns
#BreastCancer$age <- factor(BreastCancer$age, levels = c("10-19", "20-29", "30-39", "40-49", "50-59", "60-69", "70-79", "80-89", "90-99"))
BreastCancer$menopause <- factor(BreastCancer$menopause, levels = c("lt40", "ge40", "premeno"))
#BreastCancer$tumor.size <- factor(BreastCancer$tumor.size, levels = c("0-4", "5-9", "10-14", "15-19", "20-24", "25-29", "30-34", "35-39", "40-44", "45-49", "50-54", "55-59"))
#BreastCancer$inv.nodes <- factor(BreastCancer$inv.nodes, levels = c("0-2", "3-5", "6-8", "9-11", "12-14", "15-17", "18-20", "21-23", "24-26", "27-29", "30-32", "33-35", "36-39"))
BreastCancer$nodecaps <- factor(BreastCancer$nodecaps, levels = c("yes", "no"))
BreastCancer$breast <- factor(BreastCancer$breast, levels = c("left", "right"))
BreastCancer$breastquad <- factor(BreastCancer$breastquad, levels = c("leftup", "leftlow", "rightup", "rightlow", "central"))
BreastCancer$irradiat <- factor(BreastCancer$irradiat, levels = c("yes", "no"))
# Convert factor levels to numeric values
BreastCancer$age <- as.numeric(BreastCancer$age)
BreastCancer$menopause <- as.numeric(BreastCancer$menopause)
BreastCancer$tumorsize <- as.numeric(BreastCancer$tumorsize)
BreastCancer$invnodes <- as.numeric(BreastCancer$invnodes)
BreastCancer$nodecaps <- as.numeric(BreastCancer$nodecaps)
BreastCancer$breast <- as.numeric(BreastCancer$breast)
BreastCancer$breastquad <- as.numeric(BreastCancer$breastquad)
BreastCancer$irradiat <- as.numeric(BreastCancer$irradiat)
# Convert "no-recurrence-events" to 0 and "recurrence-events" to 1
BreastCancer$Class <- as.numeric(ifelse(BreastCancer$Class == "recurrence-events", 1, 0))
# Set seed for reproducibility
set.seed(530)
Random.seed <- c("Mersenne-Twister", 530)
# Split data into training and testing sets
BreastCancer.split <- sample(1:nrow(BreastCancer), size = nrow(BreastCancer) * 0.8)
BreastCancer.train <- BreastCancer[BreastCancer.split,]
BreastCancer.test <- BreastCancer[-BreastCancer.split,]
# Convert data to matrix
dtrain <- xgb.DMatrix(data = as.matrix(BreastCancer.train[, -1]), label = BreastCancer.train$Class)
dtest <- xgb.DMatrix(data = as.matrix(BreastCancer.test[, -1]))
# Set hyperparameters
params <- list(
objective = "binary:logistic",  # For binary classification
eval_metric = "error"            # Evaluation metric
)
xgb_model_cv <- xgb.cv(data = dtrain,
params = params,
nfold = 5,
nrounds = 6,            # Number of boosting rounds
early_stopping_rounds = 5,
seed = 530,
metrics = "error",       # Specify the evaluation metric for cross-validation
maximize = FALSE)        # Error is minimized
# Get the cross-validation error for each boosting round
cv_errors <- xgb_model_cv$evaluation_log$test_error_mean
# Find the optimal number of boosting rounds that minimizes the cross-validation error
best_nrounds <- which.min(cv_errors)
# Train the final model with the optimal number of boosting rounds
xgb_model <- xgboost(data = dtrain,
params = params,
nrounds = best_nrounds)
# Make predictions on the test data
predictions <- predict(xgb_model, dtest)
# Convert predictions to class labels
predicted_labels <- ifelse(predictions > 0.5, 1, 0)
# Evaluate the model
accuracy <- mean(predicted_labels == BreastCancer.test$Class)
# Predictions on the train set
predictions_train <- predict(xgb_model, as.matrix(BreastCancer.train[, -1]))
predictions_train <- ifelse(predictions_train > 0.5, 1, 0)
# Confusion matrix for train set
conf_mat_train <- table(BreastCancer.train$Class, predictions_train)
acc_xgb_train <- sum(diag(conf_mat_train)) / sum(conf_mat_train)
sensitivity_xgb_train <- conf_mat_train[1, 1] / sum(conf_mat_train[1, ])
specificity_xgb_train <- conf_mat_train[2, 2] / sum(conf_mat_train[2, ])
ppv_xgb_train <- conf_mat_train[1, 1] / sum(conf_mat_train[, 1])
npv_xgb_train <- conf_mat_train[2, 2] / sum(conf_mat_train[, 2])
# Predictions on the test set
predictions_test <- predict(xgb_model, as.matrix(BreastCancer.test[, -1]))
predictions_test <- ifelse(predictions_test > 0.5, 1, 0)
# Confusion matrix for test set
conf_mat_test <- table(BreastCancer.test$Class, predictions_test)
acc_xgb_test <- sum(diag(conf_mat_test)) / sum(conf_mat_test)
sensitivity_xgb_test <- conf_mat_test[1, 1] / sum(conf_mat_test[1, ])
specificity_xgb_test <- conf_mat_test[2, 2] / sum(conf_mat_test[2, ])
ppv_xgb_test <- conf_mat_test[1, 1] / sum(conf_mat_test[, 1])
npv_xgb_test <- conf_mat_test[2, 2] / sum(conf_mat_test[, 2])
# Confusion matrix for all dataset
predictions_all <- predict(xgb_model, as.matrix(BreastCancer[, -1]))
predictions_all <- ifelse(predictions_all > 0.5, 1, 0)
conf_mat_all <- table(BreastCancer$Class, predictions_all)
acc_xgb_all <- sum(diag(conf_mat_all)) / sum(conf_mat_all)
sensitivity_xgb_all <- conf_mat_all[1, 1] / sum(conf_mat_all[1, ])
specificity_xgb_all <- conf_mat_all[2, 2] / sum(conf_mat_all[2, ])
ppv_xgb_all <- conf_mat_all[1, 1] / sum(conf_mat_all[, 1])
npv_xgb_all <- conf_mat_all[2, 2] / sum(conf_mat_all[, 2])
# Print the metrics for the XGBoost model
acc_xgb_train
sensitivity_xgb_train
specificity_xgb_train
ppv_xgb_train
npv_xgb_train
acc_xgb_test
sensitivity_xgb_test
specificity_xgb_test
ppv_xgb_test
npv_xgb_test
acc_xgb_all
sensitivity_xgb_all
specificity_xgb_all
ppv_xgb_all
npv_xgb_all
# Predict probabilities for train, test, and all datasets
train_pred_prob <- predict(xgb_model, as.matrix(BreastCancer.train[, -1]))
test_pred_prob <- predict(xgb_model, as.matrix(BreastCancer.test[, -1]))
all_pred_prob <- predict(xgb_model, as.matrix(BreastCancer[, -1]))
# Calculate ROC curves
train_roc <- roc(BreastCancer.train$Class, train_pred_prob)
test_roc <- roc(BreastCancer.test$Class, test_pred_prob)
all_roc <- roc(BreastCancer$Class, all_pred_prob)
# Check the number of points in the ROC curve
num_points <- length(train_roc$thresholds)
print(num_points)
summary(train_pred_prob)
# Check the range
min_prob <- min(train_pred_prob)
max_prob <- max(train_pred_prob)
print(min_prob)
print(max_prob)
# Smooth ROC curves
smoothed_train_roc <- smooth(train_roc)
smoothed_test_roc <- smooth(test_roc)
smoothed_all_roc <- smooth(all_roc)
# Plot ROC curves
plot(train_roc, col = "blue", main = "ROC Curves for XGBoost",
xlab = "False Positive Rate", ylab = "True Positive Rate")
plot(smoothed_train_roc, col = "lightblue", add = TRUE)
plot(test_roc, col = "red", add = TRUE)
plot(smoothed_test_roc, col = "pink", add = TRUE)
plot(all_roc, col = "green", add = TRUE)
plot(smoothed_all_roc, col = "lightgreen", add = TRUE)
# Calculate AUC for each curve
train_auc <- round(auc(train_roc), 2)
test_auc <- round(auc(test_roc), 2)
all_auc <- round(auc(all_roc), 2)
smoothed_train_auc <- round(auc(smoothed_train_roc), 2)
smoothed_test_auc <- round(auc(smoothed_test_roc), 2)
smoothed_all_auc <- round(auc(smoothed_all_roc), 2)
# Add legend with AUC values
legend("bottomright", legend = c(
paste("Train (Empirical)", "AUC =", train_auc),
paste("Train (Smoothed)", "AUC =", smoothed_train_auc),
paste("Test (Empirical)", "AUC =", test_auc),
paste("Test (Smoothed)", "AUC =", smoothed_test_auc),
paste("All (Empirical)", "AUC =", all_auc),
paste("All (Smoothed)", "AUC =", smoothed_all_auc)
), col = c("blue", "lightblue", "red", "pink", "green", "lightgreen"), lwd = 2, cex = 0.6)
